{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38039231-5754-40a4-a0ae-f4d4469627de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "print(\"Project path added to system path.\")\n",
    "\n",
    "from src.api.anthropic_client import AnthropicClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37411c44-0ee0-4f29-8644-c27b99fa4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize the client and conversation state\n",
    "client = AnthropicClient()\n",
    "print(f\"AnthropicClient initialized with model: {client.model}\")\n",
    "\n",
    "# Initialize conversation state\n",
    "conversation_state = {\n",
    "    \"messages\": [],  # Will store the conversation history\n",
    "    \"summary\": \"\",   # Will store the latest conversation summary\n",
    "    \"shared_files\": [],  # Will track which files have been shared\n",
    "    \"last_updated\": datetime.now().isoformat(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61c34-acb0-4d43-802b-76974196f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Function to send a message to Claude with conversation history\n",
    "def ask_claude(prompt, include_history=True, include_summary=True, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Send a message to Claude with optional conversation history and summary.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The new prompt to send to Claude\n",
    "        include_history (bool): Whether to include message history\n",
    "        include_summary (bool): Whether to include the conversation summary\n",
    "        max_tokens (int): Maximum tokens in the response\n",
    "        \n",
    "    Returns:\n",
    "        dict: Formatted response from Claude\n",
    "    \"\"\"\n",
    "    full_prompt = \"\"\n",
    "    \n",
    "    # Add summary if requested and available\n",
    "    if include_summary and conversation_state[\"summary\"]:\n",
    "        full_prompt += \"# Previous Conversation Summary\\n\"\n",
    "        full_prompt += conversation_state[\"summary\"]\n",
    "        full_prompt += \"\\n\\n\"\n",
    "    \n",
    "    # Add conversation history if requested\n",
    "    if include_history and conversation_state[\"messages\"]:\n",
    "        full_prompt += \"# Previous Messages\\n\"\n",
    "        # Include up to last 3 message pairs to avoid token limits\n",
    "        for i in range(max(0, len(conversation_state[\"messages\"])-6), len(conversation_state[\"messages\"])):\n",
    "            msg = conversation_state[\"messages\"][i]\n",
    "            full_prompt += f\"{'Human' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}\\n\\n\"\n",
    "        \n",
    "        full_prompt += \"# New Question\\n\"\n",
    "    \n",
    "    # Add the new prompt\n",
    "    full_prompt += prompt\n",
    "    \n",
    "    print(f\"Sending to Claude (with{'out' if not include_history else ''} history, with{'out' if not include_summary else ''} summary)\")\n",
    "    \n",
    "    # Get response from Claude\n",
    "    response = client.send_message(full_prompt, max_tokens=max_tokens)\n",
    "    \n",
    "    # Extract text content\n",
    "    text_content = \"\"\n",
    "    for block in response.content:\n",
    "        if block.type == \"text\":\n",
    "            text_content += block.text\n",
    "    \n",
    "    # Update conversation history\n",
    "    conversation_state[\"messages\"].append({\"role\": \"user\", \"content\": prompt})\n",
    "    conversation_state[\"messages\"].append({\"role\": \"assistant\", \"content\": text_content})\n",
    "    conversation_state[\"last_updated\"] = datetime.now().isoformat()\n",
    "    \n",
    "    return {\n",
    "        \"message_id\": response.id,\n",
    "        \"model\": response.model,\n",
    "        \"content\": text_content,\n",
    "        \"tokens_used\": len(full_prompt.split()) // 3  # Rough estimate of tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fdeaa8-4c01-495d-a56c-a9acee599ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function to extract and save markdown content from Claude's response\n",
    "def extract_markdown(response_text):\n",
    "    \"\"\"Extract markdown sections from Claude's response text\"\"\"\n",
    "    # Look for markdown blocks between triple backticks\n",
    "    code_blocks = re.findall(r'```(?:markdown)?\\s*([\\s\\S]*?)```', response_text)\n",
    "    \n",
    "    # Also look for potential markdown sections that start with headings\n",
    "    heading_blocks = re.findall(r'(?:^|\\n)# (.*?)(?:\\n|$)([\\s\\S]*?)(?=(?:\\n# |$))', response_text)\n",
    "    \n",
    "    artifacts = []\n",
    "    \n",
    "    # Process code blocks\n",
    "    for i, block in enumerate(code_blocks):\n",
    "        artifacts.append({\n",
    "            \"type\": \"markdown_code_block\",\n",
    "            \"content\": block.strip(),\n",
    "            \"index\": i\n",
    "        })\n",
    "    \n",
    "    # Process heading sections\n",
    "    for i, (heading, content) in enumerate(heading_blocks):\n",
    "        # Skip if this content is already included in a code block\n",
    "        if not any(content.strip() in block for block in code_blocks):\n",
    "            artifacts.append({\n",
    "                \"type\": \"markdown_section\",\n",
    "                \"heading\": heading.strip(),\n",
    "                \"content\": f\"# {heading.strip()}\\n\\n{content.strip()}\",\n",
    "                \"index\": i\n",
    "            })\n",
    "    \n",
    "    return artifacts\n",
    "\n",
    "def save_artifact(artifact, folder=\"extracted_artifacts\"):\n",
    "    \"\"\"Save an artifact to a file\"\"\"\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    # Generate filename based on heading or index\n",
    "    if artifact['type'] == 'markdown_section' and 'heading' in artifact:\n",
    "        # Clean up the heading to make it a valid filename\n",
    "        filename = \"\".join(c if c.isalnum() or c in \" -_\" else \"_\" for c in artifact['heading'])\n",
    "        filename = filename.replace(\" \", \"_\").lower()\n",
    "    else:\n",
    "        filename = f\"artifact_{artifact['index']}\"\n",
    "    \n",
    "    # Add extension and ensure uniqueness\n",
    "    base_filename = os.path.join(folder, f\"{filename}.md\")\n",
    "    final_filename = base_filename\n",
    "    counter = 1\n",
    "    \n",
    "    while os.path.exists(final_filename):\n",
    "        final_filename = os.path.join(folder, f\"{filename}_{counter}.md\")\n",
    "        counter += 1\n",
    "    \n",
    "    # Write the content to the file\n",
    "    with open(final_filename, 'w') as f:\n",
    "        f.write(artifact['content'])\n",
    "    \n",
    "    return final_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8ab16-708a-47f8-ad92-6d28ab449c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: File and project management functions\n",
    "def get_project_structure(root_dir='.', ignore_patterns=None):\n",
    "    \"\"\"\n",
    "    Generate a summary of the project's file structure\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import fnmatch\n",
    "    \n",
    "    if ignore_patterns is None:\n",
    "        ignore_patterns = [\n",
    "            '__pycache__', \n",
    "            '*.pyc', \n",
    "            '.git', \n",
    "            '.ipynb_checkpoints', \n",
    "            'venv',\n",
    "            '*.egg-info'\n",
    "        ]\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        # Skip ignored directories using fnmatch instead of regex\n",
    "        dirs_to_keep = []\n",
    "        for d in dirs:\n",
    "            if not any(fnmatch.fnmatch(d, pattern) for pattern in ignore_patterns):\n",
    "                dirs_to_keep.append(d)\n",
    "        dirs[:] = dirs_to_keep\n",
    "        \n",
    "        # Use relative path for better readability\n",
    "        rel_path = os.path.relpath(root, root_dir)\n",
    "        if rel_path == '.':\n",
    "            result.append(\"Project Root/\")\n",
    "            level = 0\n",
    "        else:\n",
    "            level = rel_path.count(os.sep) + 1\n",
    "            indent = ' ' * 4 * (level - 1)\n",
    "            result.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        \n",
    "        # Add files\n",
    "        sub_indent = ' ' * 4 * level\n",
    "        for file in sorted(files):\n",
    "            if not any(fnmatch.fnmatch(file, pattern) for pattern in ignore_patterns):\n",
    "                result.append(f\"{sub_indent}{file}\")\n",
    "    \n",
    "    return '\\n'.join(result)\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    \"\"\"Read and return the content of a file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "def include_file_in_prompt(file_path, max_length=None):\n",
    "    \"\"\"Format a file for inclusion in a prompt to Claude\"\"\"\n",
    "    content = read_file_content(file_path)\n",
    "    \n",
    "    # Truncate if specified\n",
    "    if max_length and len(content) > max_length:\n",
    "        content = content[:max_length] + \"\\n...(truncated)...\"\n",
    "    \n",
    "    # Format the file content for inclusion in prompt\n",
    "    formatted = f\"\"\"\n",
    "<file path=\"{file_path}\">\n",
    "```\n",
    "{content}\n",
    "```\n",
    "</file>\n",
    "\"\"\"\n",
    "    return formatted\n",
    "\n",
    "def share_files_with_claude(file_paths, prompt_prefix=\"Please review these files:\", prompt_suffix=\"\"):\n",
    "    \"\"\"Share multiple files with Claude and ask for analysis\"\"\"\n",
    "    prompt = prompt_prefix + \"\\n\\n\"\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        prompt += include_file_in_prompt(file_path)\n",
    "        # Track that we've shared this file\n",
    "        if file_path not in conversation_state[\"shared_files\"]:\n",
    "            conversation_state[\"shared_files\"].append(file_path)\n",
    "    \n",
    "    prompt += \"\\n\" + prompt_suffix\n",
    "    \n",
    "    return ask_claude(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ea8ca-5b34-4a20-b6ce-16169edd2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Summarization functions\n",
    "def generate_conversation_summary():\n",
    "    \"\"\"Ask Claude to summarize the conversation so far\"\"\"\n",
    "    if len(conversation_state[\"messages\"]) < 2:\n",
    "        print(\"Not enough conversation to summarize.\")\n",
    "        return\n",
    "    \n",
    "    # Gather recent conversation\n",
    "    recent_convo = \"\"\n",
    "    for i, msg in enumerate(conversation_state[\"messages\"]):\n",
    "        role = \"Human\" if msg[\"role\"] == \"user\" else \"Assistant\"\n",
    "        recent_convo += f\"{role}: {msg['content']}\\n\\n\"\n",
    "    \n",
    "    summary_prompt = f\"\"\"\n",
    "Please provide a concise summary of our conversation so far. Focus on:\n",
    "1. The main project goal (Claude Artifacts Automation)\n",
    "2. Current progress and implementation details\n",
    "3. Key decisions made\n",
    "4. Current issues or questions being addressed\n",
    "\n",
    "Here's the conversation to summarize:\n",
    "\n",
    "{recent_convo}\n",
    "\"\"\"\n",
    "    \n",
    "    # We don't include history/summary to avoid recursion\n",
    "    response = ask_claude(summary_prompt, include_history=False, include_summary=False)\n",
    "    \n",
    "    # Save the summary\n",
    "    conversation_state[\"summary\"] = response[\"content\"]\n",
    "    print(\"Conversation summary updated.\")\n",
    "    \n",
    "    return response[\"content\"]\n",
    "\n",
    "def save_conversation_state(filename=\"claude_conversation_state.json\"):\n",
    "    \"\"\"Save the current conversation state to a file\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(conversation_state, f, indent=2)\n",
    "    print(f\"Conversation state saved to {filename}\")\n",
    "\n",
    "def load_conversation_state(filename=\"claude_conversation_state.json\"):\n",
    "    \"\"\"Load conversation state from a file\"\"\"\n",
    "    global conversation_state\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            conversation_state = json.load(f)\n",
    "        print(f\"Conversation state loaded from {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Using empty conversation state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400dc16e-812a-4850-94f1-16c64de17320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test with a simple prompt\n",
    "# Uncomment to run a test\n",
    "response = ask_claude(\"Hello Claude, what capabilities does this notebook provide for working with the Claude API?\")\n",
    "print(f\"\\nMessage ID: {response['message_id']}\")\n",
    "print(f\"Model: {response['model']}\")\n",
    "print(\"\\n--- Claude's Response ---\")\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b606e-c0f6-4920-a026-f3ece9f56861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Example usage - sharing project files\n",
    "project_structure = get_project_structure()\n",
    "print(project_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf512b4-d234-48d2-9868-65dd65ef33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Example of sharing multiple files and asking for analysis\n",
    "key_files = [\n",
    "   \"./src/api/anthropic_client.py\",\n",
    "   \"./config/credentials.json\"\n",
    "]\n",
    "response = share_files_with_claude(\n",
    "   key_files, \n",
    "   prompt_prefix=\"Please review these files from my Claude Artifacts Automation project:\", \n",
    "   prompt_suffix=\"What improvements would you suggest for the AnthropicClient class?\"\n",
    ")\n",
    "print(response[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cf6f1-53ec-4ade-aa43-bbff04587bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Generating and saving a summary\n",
    "summary = generate_conversation_summary()\n",
    "print(\"--- Conversation Summary ---\")\n",
    "print(summary)\n",
    "save_conversation_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6666dbc-d9a2-4029-9bd5-22489b6071d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
